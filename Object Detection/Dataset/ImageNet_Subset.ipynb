{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpwcQfK5oOeR"
   },
   "source": [
    "Creation of a subset of ImageNet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LbiDjXDToT4Z",
    "outputId": "73bd1191-c64b-4d8b-b8d5-53d95bcd1f8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/MyDrive\n"
     ]
    }
   ],
   "source": [
    "# use storage in drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "%cd /content/drive/MyDrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V11I-CXLDugr",
    "outputId": "1c80242d-874d-42d7-e099-ad37c20bf21e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'part-of-imagenet'...\n",
      "remote: Enumerating objects: 12, done.\u001b[K\n",
      "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
      "remote: Total 3753 (delta 3), reused 7 (delta 3), pack-reused 3741\u001b[K\n",
      "Receiving objects: 100% (3753/3753), 42.49 MiB | 16.66 MiB/s, done.\n",
      "Resolving deltas: 100% (69/69), done.\n",
      "Checking out files: 100% (3633/3633), done.\n"
     ]
    }
   ],
   "source": [
    "# take a part of ImageNet. Use of SanjyotZade's Toolkit\n",
    "!git clone https://github.com/SanjyotZade/part-of-imagenet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "w4Wwh3LkDyDy",
    "outputId": "d0687215-b28b-4905-c5bc-737e7208047d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/part-of-imagenet\n",
      "Collecting appnope==0.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/87/a9/7985e6a53402f294c8f0e8eff3151a83f1fb901fa92909bb3ff29b4d22af/appnope-0.1.0-py2.py3-none-any.whl\n",
      "Collecting attrs==19.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/23/96/d828354fa2dbdf216eaa7b7de0db692f12c234f7ef888cc14980ef40d1d2/attrs-19.1.0-py2.py3-none-any.whl\n",
      "Collecting backcall==0.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/84/71/c8ca4f5bb1e08401b916c68003acf0a0655df935d74d93bf3f3364b310e0/backcall-0.1.0.tar.gz\n",
      "Collecting beautifulsoup4==4.8.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/b7/34eec2fe5a49718944e215fde81288eec1fa04638aa3fb57c1c6cd0f98c3/beautifulsoup4-4.8.0-py3-none-any.whl (97kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 7.4MB/s \n",
      "\u001b[?25hCollecting bleach==3.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/05/27e1466475e816d3001efb6e0a85a819be17411420494a1e602c36f8299d/bleach-3.1.0-py2.py3-none-any.whl (157kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 26.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: bs4==0.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 6)) (0.0.1)\n",
      "Requirement already satisfied: contextlib2==0.5.5 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 7)) (0.5.5)\n",
      "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 8)) (0.10.0)\n",
      "Collecting Cython==0.29.13\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/d3/03a01bcf424eb86d3e9d818e2082ced2d512001af89183fca6f550c32bc2/Cython-0.29.13-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 27.5MB/s \n",
      "\u001b[?25hCollecting decorator==4.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/5f/88/0075e461560a1e750a0dcbf77f1d9de775028c37a19a346a6c565a257399/decorator-4.4.0-py2.py3-none-any.whl\n",
      "Collecting defusedxml==0.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/06/74/9b387472866358ebc08732de3da6dc48e44b0aacd2ddaa5cb85ab7e986a2/defusedxml-0.6.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: entrypoints==0.3 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 12)) (0.3)\n",
      "Collecting ipykernel==5.1.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/35/dd97fbb48d4e6b5ae97307497e31e46691adc2feedb6279d29fc1c8ad9c1/ipykernel-5.1.1-py3-none-any.whl (114kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 54.4MB/s \n",
      "\u001b[?25hCollecting ipython==7.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/c4/a79582814bdfe92bfca4d286a729304ffdf13f5135132cfcaea13cf1b2b3/ipython-7.7.0-py3-none-any.whl (774kB)\n",
      "\u001b[K     |████████████████████████████████| 778kB 51.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 15)) (0.2.0)\n",
      "Collecting ipywidgets==7.5.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a0/dbcf5881bb2f51e8db678211907f16ea0a182b232c591a6d6f276985ca95/ipywidgets-7.5.1-py2.py3-none-any.whl (121kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 57.5MB/s \n",
      "\u001b[?25hCollecting jedi==0.14.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/06/e906725a5b3ad7996bbdbfe9958aab75db64ef84bbaabefe47574de58865/jedi-0.14.1-py2.py3-none-any.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 51.4MB/s \n",
      "\u001b[?25hCollecting Jinja2==2.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/e7/fd8b501e7a6dfe492a433deb7b9d833d39ca74916fa8bc63dd1a4947a671/Jinja2-2.10.1-py2.py3-none-any.whl (124kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 55.0MB/s \n",
      "\u001b[?25hCollecting jsonschema==3.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/69/df679dfbdd051568b53c38ec8152a3ab6bc533434fc7ed11ab034bf5e82f/jsonschema-3.0.1-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 8.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 20)) (1.0.0)\n",
      "Collecting jupyter-client==5.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/4c/bf613864ae0644e2ac7d4a40bd209c40c8c71e3dc88d5f1d0aa92a68e716/jupyter_client-5.3.1-py2.py3-none-any.whl (91kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 11.4MB/s \n",
      "\u001b[?25hCollecting jupyter-console==6.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/cb/ee/6374ae8c21b7d0847f9c3722dcdfac986b8e54fa9ad9ea66e1eb6320d2b8/jupyter_console-6.0.0-py2.py3-none-any.whl\n",
      "Collecting jupyter-core==4.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/25/6ffb0f6e57fa6ef5d2f814377133b361b42a6dd39105f4885a4f1666c2c3/jupyter_core-4.5.0-py2.py3-none-any.whl (78kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 11.7MB/s \n",
      "\u001b[?25hCollecting kiwisolver==1.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/f8/518fb0bb89860eea6ff1b96483fbd9236d5ee991485d0f3eceff1770f654/kiwisolver-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (90kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 11.3MB/s \n",
      "\u001b[?25hCollecting lxml==4.4.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/a8/40115c84414c017e1a293f331709eb7534303d3ccd11ef805ac09b1481e7/lxml-4.4.1-cp37-cp37m-manylinux1_x86_64.whl (5.7MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8MB 56.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe==1.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 26)) (1.1.1)\n",
      "Collecting matplotlib==3.1.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/7a/60bd79c5d79559150f8bba866dd7d434f0a170312e4d15e8aefa5faba294/matplotlib-3.1.1-cp37-cp37m-manylinux1_x86_64.whl (13.1MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1MB 26.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: mistune==0.8.4 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 28)) (0.8.4)\n",
      "Collecting nbconvert==5.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/e7/f46c9d65f149271e47fca6ab084ef5c6e4cb1870f4c5cce6690feac55231/nbconvert-5.5.0-py2.py3-none-any.whl (447kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 40.8MB/s \n",
      "\u001b[?25hCollecting nbformat==4.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/27/9a654d2b6cc1eaa517d1c5a4405166c7f6d72f04f6e7eea41855fe808a46/nbformat-4.4.0-py2.py3-none-any.whl (155kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 57.2MB/s \n",
      "\u001b[?25hCollecting notebook==6.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/b6/a6189ca7146482d93c912dbe6c65db0f264c1c88f707feea3683caa6c1f8/notebook-6.0.0-py3-none-any.whl (9.0MB)\n",
      "\u001b[K     |████████████████████████████████| 9.0MB 18.8MB/s \n",
      "\u001b[?25hCollecting numpy==1.17.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/e0/46e2f0540370f2661b044647fa447fef2ecbcc8f7cdb4329ca2feb03fb23/numpy-1.17.2-cp37-cp37m-manylinux1_x86_64.whl (20.3MB)\n",
      "\u001b[K     |████████████████████████████████| 20.3MB 1.4MB/s \n",
      "\u001b[?25hCollecting pandas==0.25.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/ab/ea76361f9d3e732e114adcd801d2820d5319c23d0ac5482fa3b412db217e/pandas-0.25.1-cp37-cp37m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4MB 27.7MB/s \n",
      "\u001b[?25hCollecting pandocfilters==1.4.2\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/ea/236e2584af67bb6df960832731a6e5325fd4441de001767da328c33368ce/pandocfilters-1.4.2.tar.gz\n",
      "Collecting parso==0.5.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/bd/bf4e5bd01d79906e5b945a7af033154da49fd2b0d5b5c705a21330323305/parso-0.5.1-py2.py3-none-any.whl (95kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 13.3MB/s \n",
      "\u001b[?25hCollecting pexpect==4.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/3e/377007e3f36ec42f1b84ec322ee12141a9e10d808312e5738f52f80a232c/pexpect-4.7.0-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 8.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 37)) (0.7.5)\n",
      "Collecting Pillow==6.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/da/2bd281c875686230eabc13d20ab590ea617563b0e746abfb0698c4d5b645/Pillow-6.1.0-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 43.6MB/s \n",
      "\u001b[?25hCollecting prometheus-client==0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/23/41a5a24b502d35a4ad50a5bb7202a5e1d9a0364d0c12f56db3dbf7aca76d/prometheus_client-0.7.1.tar.gz\n",
      "Collecting prompt-toolkit==2.0.9\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a7/9b1dd14ef45345f186ef69d175bdd2491c40ab1dfa4b2b3e4352df719ed7/prompt_toolkit-2.0.9-py3-none-any.whl (337kB)\n",
      "\u001b[K     |████████████████████████████████| 337kB 52.8MB/s \n",
      "\u001b[?25hCollecting ptyprocess==0.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/29/605c2cc68a9992d18dada28206eeada56ea4bd07a239669da41674648b6f/ptyprocess-0.6.0-py2.py3-none-any.whl\n",
      "Collecting Pygments==2.4.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/73/1dfa428150e3ccb0fa3e68db406e5be48698f2a979ccbcec795f28f44048/Pygments-2.4.2-py2.py3-none-any.whl (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 46.9MB/s \n",
      "\u001b[?25hCollecting pyparsing==2.4.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/fa/0160cd525c62d7abd076a070ff02b2b94de589f1a9789774f17d7c54058e/pyparsing-2.4.2-py2.py3-none-any.whl (65kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 9.8MB/s \n",
      "\u001b[?25hCollecting pyrsistent==0.15.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/66/b2638d96a2d128b168d0dba60fdc77b7800a9b4a5340cefcc5fc4eae6295/pyrsistent-0.15.4.tar.gz (107kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 57.0MB/s \n",
      "\u001b[?25hCollecting python-dateutil==2.8.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 52.2MB/s \n",
      "\u001b[?25hCollecting pytz==2019.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/76/46d697698a143e05f77bec5a526bf4e56a0be61d63425b68f4ba553b51f2/pytz-2019.2-py2.py3-none-any.whl (508kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 50.1MB/s \n",
      "\u001b[?25hCollecting pyzmq==18.0.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/43/ac5473e08294fd1fc512e54c39b702de1c848391f9b2d073279f5dc7a986/pyzmq-18.0.2-cp37-cp37m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 45.4MB/s \n",
      "\u001b[?25hCollecting qtconsole==4.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/42/2999d79d012923a5b1503b981c55cb2a0105e25c8b86d23c1d2d1ba6310c/qtconsole-4.5.2-py2.py3-none-any.whl (119kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 53.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: Send2Trash==1.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 49)) (1.5.0)\n",
      "Collecting six==1.12.0\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting soupsieve==1.9.3\n",
      "  Downloading https://files.pythonhosted.org/packages/0b/44/0474f2207fdd601bb25787671c81076333d2c80e6f97e92790f8887cf682/soupsieve-1.9.3-py2.py3-none-any.whl\n",
      "Collecting terminado==0.8.2\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/56/80ea7fa66565fa75ae21ce0c16bc90067530e5d15e48854afcc86585a391/terminado-0.8.2-py2.py3-none-any.whl\n",
      "Collecting testpath==0.4.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/a4/162f9ebb6489421fe46dcca2ae420369edfee4b563c668d93cb4605d12ba/testpath-0.4.2-py2.py3-none-any.whl (163kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 60.6MB/s \n",
      "\u001b[?25hCollecting tornado==6.0.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/78/2d2823598496127b21423baffaa186b668f73cd91887fcef78b6eade136b/tornado-6.0.3.tar.gz (482kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 48.5MB/s \n",
      "\u001b[?25hCollecting tqdm==4.35.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/88/d3213e2f3492daf09d8b41631ad6899f56db17ce83ea9c8a579902bafe5e/tqdm-4.35.0-py2.py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
      "\u001b[?25hCollecting traitlets==4.3.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/d6/abcb22de61d78e2fc3959c964628a5771e47e7cc60d53e9342e21ed6cc9a/traitlets-4.3.2-py2.py3-none-any.whl (74kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 12.0MB/s \n",
      "\u001b[?25hCollecting wcwidth==0.1.7\n",
      "  Downloading https://files.pythonhosted.org/packages/7e/9f/526a6947247599b084ee5232e4f9190a38f398d7300d866af3ab571a5bfe/wcwidth-0.1.7-py2.py3-none-any.whl\n",
      "Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 58)) (0.5.1)\n",
      "Requirement already satisfied: widgetsnbextension==3.5.1 in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 59)) (3.5.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==7.7.0->-r requirement.txt (line 14)) (54.2.0)\n",
      "Building wheels for collected packages: backcall, pandocfilters, prometheus-client, pyrsistent, tornado\n",
      "  Building wheel for backcall (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for backcall: filename=backcall-0.1.0-cp37-none-any.whl size=10411 sha256=d8b113777867a4ac8dc9090b4b98ebeba2f12591f8bb9674bd8fde07124f5a3b\n",
      "  Stored in directory: /root/.cache/pip/wheels/98/b0/dd/29e28ff615af3dda4c67cab719dd51357597eabff926976b45\n",
      "  Building wheel for pandocfilters (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pandocfilters: filename=pandocfilters-1.4.2-cp37-none-any.whl size=7857 sha256=b97c8e9110a1d07469f34248af0adad3522df7f16a6218c9137f6a2fa7045b1d\n",
      "  Stored in directory: /root/.cache/pip/wheels/39/01/56/f1b08a6275acc59e846fa4c1e1b65dbc1919f20157d9e66c20\n",
      "  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-cp37-none-any.whl size=41404 sha256=05ab04205be56858fcfc94f8cb565223a03f73d601a9165cfe16b8d4db76b591\n",
      "  Stored in directory: /root/.cache/pip/wheels/1c/54/34/fd47cd9b308826cc4292b54449c1899a30251ef3b506bc91ea\n",
      "  Building wheel for pyrsistent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyrsistent: filename=pyrsistent-0.15.4-cp37-cp37m-linux_x86_64.whl size=98572 sha256=65e1bd93592a058d3bf4ee78d6270d9f238489ed7c1ba68f1203543db95be0da\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/46/00/6d471ef0b813e3621f0abe6cb723c20d529d39a061de3f7c51\n",
      "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tornado: filename=tornado-6.0.3-cp37-cp37m-linux_x86_64.whl size=424112 sha256=2aa05e0db155686968e58232a2b85285b92b51305376f47379e00a929766f04e\n",
      "  Stored in directory: /root/.cache/pip/wheels/84/bf/40/2f6ef700f48401ca40e5e3dd7d0e3c0a90e064897b7fe5fc08\n",
      "Successfully built backcall pandocfilters prometheus-client pyrsistent tornado\n",
      "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.17.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.4.1 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.35.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: nbclient 0.5.3 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: nbclient 0.5.3 has requirement nbformat>=5.0, but you'll have nbformat 4.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.7.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement notebook~=5.3.0; python_version >= \"3.0\", but you'll have notebook 6.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.25.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=5.1.0; python_version >= \"3.0\", but you'll have tornado 6.0.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-api-python-client 1.12.8 has requirement six<2dev,>=1.13.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-api-core 1.26.2 has requirement six>=1.13.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.25.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.35.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: bokeh 2.3.0 has requirement pillow>=7.1.0, but you'll have pillow 6.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: appnope, attrs, backcall, soupsieve, beautifulsoup4, six, bleach, Cython, decorator, defusedxml, traitlets, jupyter-core, pyzmq, python-dateutil, tornado, jupyter-client, Pygments, wcwidth, prompt-toolkit, ptyprocess, pexpect, parso, jedi, ipython, ipykernel, pyrsistent, jsonschema, nbformat, ipywidgets, Jinja2, jupyter-console, kiwisolver, lxml, numpy, pyparsing, matplotlib, pandocfilters, testpath, nbconvert, prometheus-client, terminado, notebook, pytz, pandas, Pillow, qtconsole, tqdm\n",
      "  Found existing installation: attrs 20.3.0\n",
      "    Uninstalling attrs-20.3.0:\n",
      "      Successfully uninstalled attrs-20.3.0\n",
      "  Found existing installation: backcall 0.2.0\n",
      "    Uninstalling backcall-0.2.0:\n",
      "      Successfully uninstalled backcall-0.2.0\n",
      "  Found existing installation: beautifulsoup4 4.6.3\n",
      "    Uninstalling beautifulsoup4-4.6.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.6.3\n",
      "  Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Found existing installation: bleach 3.3.0\n",
      "    Uninstalling bleach-3.3.0:\n",
      "      Successfully uninstalled bleach-3.3.0\n",
      "  Found existing installation: Cython 0.29.22\n",
      "    Uninstalling Cython-0.29.22:\n",
      "      Successfully uninstalled Cython-0.29.22\n",
      "  Found existing installation: decorator 4.4.2\n",
      "    Uninstalling decorator-4.4.2:\n",
      "      Successfully uninstalled decorator-4.4.2\n",
      "  Found existing installation: defusedxml 0.7.1\n",
      "    Uninstalling defusedxml-0.7.1:\n",
      "      Successfully uninstalled defusedxml-0.7.1\n",
      "  Found existing installation: traitlets 5.0.5\n",
      "    Uninstalling traitlets-5.0.5:\n",
      "      Successfully uninstalled traitlets-5.0.5\n",
      "  Found existing installation: jupyter-core 4.7.1\n",
      "    Uninstalling jupyter-core-4.7.1:\n",
      "      Successfully uninstalled jupyter-core-4.7.1\n",
      "  Found existing installation: pyzmq 22.0.3\n",
      "    Uninstalling pyzmq-22.0.3:\n",
      "      Successfully uninstalled pyzmq-22.0.3\n",
      "  Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Found existing installation: tornado 5.1.1\n",
      "    Uninstalling tornado-5.1.1:\n",
      "      Successfully uninstalled tornado-5.1.1\n",
      "  Found existing installation: jupyter-client 5.3.5\n",
      "    Uninstalling jupyter-client-5.3.5:\n",
      "      Successfully uninstalled jupyter-client-5.3.5\n",
      "  Found existing installation: Pygments 2.6.1\n",
      "    Uninstalling Pygments-2.6.1:\n",
      "      Successfully uninstalled Pygments-2.6.1\n",
      "  Found existing installation: wcwidth 0.2.5\n",
      "    Uninstalling wcwidth-0.2.5:\n",
      "      Successfully uninstalled wcwidth-0.2.5\n",
      "  Found existing installation: prompt-toolkit 1.0.18\n",
      "    Uninstalling prompt-toolkit-1.0.18:\n",
      "      Successfully uninstalled prompt-toolkit-1.0.18\n",
      "  Found existing installation: ptyprocess 0.7.0\n",
      "    Uninstalling ptyprocess-0.7.0:\n",
      "      Successfully uninstalled ptyprocess-0.7.0\n",
      "  Found existing installation: pexpect 4.8.0\n",
      "    Uninstalling pexpect-4.8.0:\n",
      "      Successfully uninstalled pexpect-4.8.0\n",
      "  Found existing installation: parso 0.8.1\n",
      "    Uninstalling parso-0.8.1:\n",
      "      Successfully uninstalled parso-0.8.1\n",
      "  Found existing installation: jedi 0.18.0\n",
      "    Uninstalling jedi-0.18.0:\n",
      "      Successfully uninstalled jedi-0.18.0\n",
      "  Found existing installation: ipython 5.5.0\n",
      "    Uninstalling ipython-5.5.0:\n",
      "      Successfully uninstalled ipython-5.5.0\n",
      "  Found existing installation: ipykernel 4.10.1\n",
      "    Uninstalling ipykernel-4.10.1:\n",
      "      Successfully uninstalled ipykernel-4.10.1\n",
      "  Found existing installation: pyrsistent 0.17.3\n",
      "    Uninstalling pyrsistent-0.17.3:\n",
      "      Successfully uninstalled pyrsistent-0.17.3\n",
      "  Found existing installation: jsonschema 2.6.0\n",
      "    Uninstalling jsonschema-2.6.0:\n",
      "      Successfully uninstalled jsonschema-2.6.0\n",
      "  Found existing installation: nbformat 5.1.2\n",
      "    Uninstalling nbformat-5.1.2:\n",
      "      Successfully uninstalled nbformat-5.1.2\n",
      "  Found existing installation: ipywidgets 7.6.3\n",
      "    Uninstalling ipywidgets-7.6.3:\n",
      "      Successfully uninstalled ipywidgets-7.6.3\n",
      "  Found existing installation: Jinja2 2.11.3\n",
      "    Uninstalling Jinja2-2.11.3:\n",
      "      Successfully uninstalled Jinja2-2.11.3\n",
      "  Found existing installation: jupyter-console 5.2.0\n",
      "    Uninstalling jupyter-console-5.2.0:\n",
      "      Successfully uninstalled jupyter-console-5.2.0\n",
      "  Found existing installation: kiwisolver 1.3.1\n",
      "    Uninstalling kiwisolver-1.3.1:\n",
      "      Successfully uninstalled kiwisolver-1.3.1\n",
      "  Found existing installation: lxml 4.2.6\n",
      "    Uninstalling lxml-4.2.6:\n",
      "      Successfully uninstalled lxml-4.2.6\n",
      "  Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n",
      "  Found existing installation: matplotlib 3.2.2\n",
      "    Uninstalling matplotlib-3.2.2:\n",
      "      Successfully uninstalled matplotlib-3.2.2\n",
      "  Found existing installation: pandocfilters 1.4.3\n",
      "    Uninstalling pandocfilters-1.4.3:\n",
      "      Successfully uninstalled pandocfilters-1.4.3\n",
      "  Found existing installation: testpath 0.4.4\n",
      "    Uninstalling testpath-0.4.4:\n",
      "      Successfully uninstalled testpath-0.4.4\n",
      "  Found existing installation: nbconvert 5.6.1\n",
      "    Uninstalling nbconvert-5.6.1:\n",
      "      Successfully uninstalled nbconvert-5.6.1\n",
      "  Found existing installation: prometheus-client 0.9.0\n",
      "    Uninstalling prometheus-client-0.9.0:\n",
      "      Successfully uninstalled prometheus-client-0.9.0\n",
      "  Found existing installation: terminado 0.9.3\n",
      "    Uninstalling terminado-0.9.3:\n",
      "      Successfully uninstalled terminado-0.9.3\n",
      "  Found existing installation: notebook 5.3.1\n",
      "    Uninstalling notebook-5.3.1:\n",
      "      Successfully uninstalled notebook-5.3.1\n",
      "  Found existing installation: pytz 2018.9\n",
      "    Uninstalling pytz-2018.9:\n",
      "      Successfully uninstalled pytz-2018.9\n",
      "  Found existing installation: pandas 1.1.5\n",
      "    Uninstalling pandas-1.1.5:\n",
      "      Successfully uninstalled pandas-1.1.5\n",
      "  Found existing installation: Pillow 7.1.2\n",
      "    Uninstalling Pillow-7.1.2:\n",
      "      Successfully uninstalled Pillow-7.1.2\n",
      "  Found existing installation: qtconsole 5.0.3\n",
      "    Uninstalling qtconsole-5.0.3:\n",
      "      Successfully uninstalled qtconsole-5.0.3\n",
      "  Found existing installation: tqdm 4.41.1\n",
      "    Uninstalling tqdm-4.41.1:\n",
      "      Successfully uninstalled tqdm-4.41.1\n",
      "Successfully installed Cython-0.29.13 Jinja2-2.10.1 Pillow-6.1.0 Pygments-2.4.2 appnope-0.1.0 attrs-19.1.0 backcall-0.1.0 beautifulsoup4-4.8.0 bleach-3.1.0 decorator-4.4.0 defusedxml-0.6.0 ipykernel-5.1.1 ipython-7.7.0 ipywidgets-7.5.1 jedi-0.14.1 jsonschema-3.0.1 jupyter-client-5.3.1 jupyter-console-6.0.0 jupyter-core-4.5.0 kiwisolver-1.1.0 lxml-4.4.1 matplotlib-3.1.1 nbconvert-5.5.0 nbformat-4.4.0 notebook-6.0.0 numpy-1.17.2 pandas-0.25.1 pandocfilters-1.4.2 parso-0.5.1 pexpect-4.7.0 prometheus-client-0.7.1 prompt-toolkit-2.0.9 ptyprocess-0.6.0 pyparsing-2.4.2 pyrsistent-0.15.4 python-dateutil-2.8.0 pytz-2019.2 pyzmq-18.0.2 qtconsole-4.5.2 six-1.12.0 soupsieve-1.9.3 terminado-0.8.2 testpath-0.4.2 tornado-6.0.3 tqdm-4.35.0 traitlets-4.3.2 wcwidth-0.1.7\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "IPython",
         "PIL",
         "dateutil",
         "decorator",
         "ipykernel",
         "ipywidgets",
         "jupyter_client",
         "jupyter_core",
         "kiwisolver",
         "matplotlib",
         "mpl_toolkits",
         "numpy",
         "pandas",
         "pexpect",
         "prompt_toolkit",
         "pygments",
         "pyparsing",
         "pytz",
         "six",
         "tornado",
         "traitlets",
         "wcwidth",
         "zmq"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading imagenet ncodes...\n",
      "19.0KB [00:00, 102KB/s]               \n",
      "Download complete !\n",
      "\n",
      "\n",
      "Downloading imagenet urls data...\n",
      "43.2kKB [00:09, 4.77kKB/s]               \n",
      "tcmalloc: large alloc 1073750016 bytes == 0x564e3d122000 @  0x7f28b0be62a4 0x564de5fce06c 0x564de6134f0a 0x564de5fd100c 0x564de60c299d 0x564de6044fe9 0x564de5fd269a 0x564de6040c9e 0x564de603fb0e 0x564de5fd277a 0x564de6040c9e 0x564de603fb0e 0x564de5fd277a 0x564de6040c9e 0x564de5f11d14 0x564de60421e6 0x564de603fb0e 0x564de5fd277a 0x564de6044e50 0x564de603fb0e 0x564de5fd277a 0x564de604186a 0x564de603fb0e 0x564de603f813 0x564de6109592 0x564de610990d 0x564de61097b6 0x564de60e1103 0x564de60e0dac 0x7f28af9cfbf7 0x564de60e0c8a\n",
      "tcmalloc: large alloc 1277509632 bytes == 0x564e7d124000 @  0x7f28b0be51e7 0x564de6002f48 0x564de5fcdbfc 0x564de6041a11 0x564de603fb0e 0x564de5fd277a 0x564de6040c9e 0x564de603fb0e 0x564de5fd277a 0x564de6040c9e 0x564de5f11d14 0x564de60421e6 0x564de603fb0e 0x564de5fd277a 0x564de6044e50 0x564de603fb0e 0x564de5fd277a 0x564de604186a 0x564de603fb0e 0x564de603f813 0x564de6109592 0x564de610990d 0x564de61097b6 0x564de60e1103 0x564de60e0dac 0x7f28af9cfbf7 0x564de60e0c8a\n",
      "Imagenet url data csv saved !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# install some requirements\n",
    "%cd part-of-imagenet/\n",
    "\n",
    "!pip install -r requirement.txt\n",
    "\n",
    "!python download_imagenet_prerequisites.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tr5nXGnYqM9X",
    "outputId": "4074def5-0697-42f1-aa7a-bdb07d79304d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subset ncodes data as per required ncodes...\n",
      "\n",
      "Downloading 8 images simultaneously\n",
      "3 secs is the timeout duration of an image download\n",
      "\n",
      "Category : sheep (n02411705)\n",
      "150/1273 image urls have annotations available\n",
      "Downloading 60/1273 urls with annotation\n",
      "\n",
      "100% 7/7 [00:08<00:00,  1.19s/it]\n",
      "\n",
      "Success/Present : 42/60\n",
      "HTTP/URL/No-image errors : 18/60\n",
      "Download complete in 8.507011651992798 secs\n",
      "\n",
      "\n",
      "\n",
      "Category : horse,Equuscaballus (n02374451)\n",
      "571/1402 image urls have annotations available\n",
      "122/693 xml have no image url, deleting.\n",
      "Downloading 60/1402 urls with annotation\n",
      "\n",
      "100% 7/7 [00:05<00:00,  1.27it/s]\n",
      "\n",
      "Success/Present : 49/60\n",
      "HTTP/URL/No-image errors : 11/60\n",
      "Download complete in 5.658464431762695 secs\n",
      "\n",
      "\n",
      "\n",
      "Category : cow (n01887787)\n",
      "287/1588 image urls have annotations available\n",
      "Downloading 60/1588 urls with annotation\n",
      "\n",
      "100% 7/7 [00:08<00:00,  1.23s/it]\n",
      "\n",
      "Success/Present : 51/60\n",
      "HTTP/URL/No-image errors : 9/60\n",
      "Download complete in 8.793672323226929 secs\n",
      "\n",
      "\n",
      "\n",
      "Category : person,individual,someone,somebody,mortal,soul (n00007846)\n",
      "265/1242 image urls have annotations available\n",
      "Downloading 60/1242 urls with annotation\n",
      "\n",
      "100% 7/7 [00:03<00:00,  1.87it/s]\n",
      "\n",
      "Success/Present : 48/60\n",
      "HTTP/URL/No-image errors : 12/60\n",
      "Download complete in 3.929028272628784 secs\n",
      "\n",
      "\n",
      "\n",
      "<<-- Final report -->>\n",
      "Total downloaded images: 190/240\n",
      "Total HTTP/URL/NO-file errors: 50/240\n",
      "Total writing errors: 0/240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change the ncodes.csv file(to_download=TRUE and how_many=number of images we want), depending on what classes we need and how many images per class\n",
    "# we take 4 classes(Horse, Cow, Sheep, Person) with maximum 60 images for each class, 10 of them for testing\n",
    "# classes:\n",
    "# person,individual,someonee,..  n00007846\n",
    "# cow  n01887787\n",
    "# horse, Equus caballus n02374451\n",
    "# sheep  n02411705\n",
    "# let's download 'maximum'* 60 images for each class to partial_imagenet, 45 for training and the rest for testing\n",
    "# *'maximum': ImageNet works with urls of images. Some of them or their annotations may not exist, so errors occure\n",
    "!python extract_images_as_per_tags.py --with_annotation True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnBL24Q9z2Ef",
    "outputId": "038ba883-123d-4502-b524-3deb6e4e4eef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive\n",
      "/content/drive/MyDrive/image_set4\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive\n",
    "!mkdir image_set4\n",
    "%cd image_set4\n",
    "!mkdir test\n",
    "!mkdir train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kg2d7Js7LDD1",
    "outputId": "2e9ffb83-5e83-4f80-a7a9-82fca6a29eaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sheep\n",
      "Total number of xml files before matching for sheep is 150\n",
      "Total number of jpg files before matching for sheep is 42\n",
      "Total number of xml files after matching each jpg file with its corresponding xml for sheep is 42\n",
      "Total number of jpg files after matching each jpg file with its corresponding xml for sheep is 42\n",
      "['n02411705_3880.xml', 'n02411705_4574.xml', 'n02411705_5900.xml', 'n02411705_1215.xml', 'n02411705_3363.xml', 'n02411705_946.xml', 'n02411705_5830.xml', 'n02411705_1556.xml']\n",
      "['n02411705_3880.jpg', 'n02411705_4574.jpg', 'n02411705_5900.jpg', 'n02411705_1215.jpg', 'n02411705_3363.jpg', 'n02411705_946.jpg', 'n02411705_5830.jpg', 'n02411705_1556.jpg']\n",
      "horse,Equuscaballus\n",
      "Total number of xml files before matching for horse,Equuscaballus is 571\n",
      "Total number of jpg files before matching for horse,Equuscaballus is 49\n",
      "Total number of xml files after matching each jpg file with its corresponding xml for horse,Equuscaballus is 49\n",
      "Total number of jpg files after matching each jpg file with its corresponding xml for horse,Equuscaballus is 49\n",
      "['n02374451_362.xml', 'n02374451_245.xml', 'n02374451_751.xml', 'n02374451_631.xml', 'n02374451_469.xml', 'n02374451_1062.xml', 'n02374451_260.xml', 'n02374451_490.xml', 'n02374451_240.xml', 'n02374451_116.xml']\n",
      "['n02374451_362.jpg', 'n02374451_245.jpg', 'n02374451_751.jpg', 'n02374451_631.jpg', 'n02374451_469.jpg', 'n02374451_1062.jpg', 'n02374451_260.jpg', 'n02374451_490.jpg', 'n02374451_240.jpg', 'n02374451_116.jpg']\n",
      "cow\n",
      "Total number of xml files before matching for cow is 287\n",
      "Total number of jpg files before matching for cow is 51\n",
      "Total number of xml files after matching each jpg file with its corresponding xml for cow is 51\n",
      "Total number of jpg files after matching each jpg file with its corresponding xml for cow is 51\n",
      "['n01887787_977.xml', 'n01887787_1651.xml', 'n01887787_654.xml', 'n01887787_203.xml', 'n01887787_1687.xml', 'n01887787_1742.xml', 'n01887787_182.xml', 'n01887787_585.xml', 'n01887787_591.xml', 'n01887787_60.xml']\n",
      "['n01887787_977.jpg', 'n01887787_1651.jpg', 'n01887787_654.jpg', 'n01887787_203.jpg', 'n01887787_1687.jpg', 'n01887787_1742.jpg', 'n01887787_182.jpg', 'n01887787_585.jpg', 'n01887787_591.jpg', 'n01887787_60.jpg']\n",
      "person,individual,someone,somebody,mortal,soul\n",
      "Total number of xml files before matching for person,individual,someone,somebody,mortal,soul is 265\n",
      "Total number of jpg files before matching for person,individual,someone,somebody,mortal,soul is 48\n",
      "Total number of xml files after matching each jpg file with its corresponding xml for person,individual,someone,somebody,mortal,soul is 48\n",
      "Total number of jpg files after matching each jpg file with its corresponding xml for person,individual,someone,somebody,mortal,soul is 48\n",
      "['n00007846_24599.xml', 'n00007846_21529.xml', 'n00007846_33716.xml', 'n00007846_13534.xml', 'n00007846_26886.xml', 'n00007846_27074.xml', 'n00007846_25566.xml', 'n00007846_14602.xml', 'n00007846_30171.xml', 'n00007846_20401.xml']\n",
      "['n00007846_24599.jpg', 'n00007846_21529.jpg', 'n00007846_33716.jpg', 'n00007846_13534.jpg', 'n00007846_26886.jpg', 'n00007846_27074.jpg', 'n00007846_25566.jpg', 'n00007846_14602.jpg', 'n00007846_30171.jpg', 'n00007846_20401.jpg']\n"
     ]
    }
   ],
   "source": [
    "# clean the dataset: \n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "files = os.listdir('/content/drive/MyDrive/part-of-imagenet/partial_imagenet')\n",
    "\n",
    "test_dest = r'/content/drive/MyDrive/image_set4/test'\n",
    "train_dest = r'/content/drive/MyDrive/image_set4/train'\n",
    "\n",
    "for filename in files:\n",
    "\n",
    "  print(filename)\n",
    "  test_annot = []\n",
    "   \n",
    "  # check if there's a corresponding xml file for each image, delete others\n",
    "  print('Total number of xml files before matching for', filename ,'is', len(glob.glob1('/content/drive/MyDrive/part-of-imagenet/partial_imagenet/' + filename + '/Annotation','*.xml')))\n",
    "  print('Total number of jpg files before matching for', filename ,'is', len(glob.glob1('/content/drive/MyDrive/part-of-imagenet/partial_imagenet/' + filename + '/Images','*.jpg')))\n",
    "\n",
    "  # delete images and annotations that are not pairs\n",
    "  keep_stems = set(p.stem for p in Path('/content/drive/MyDrive/part-of-imagenet/partial_imagenet/' + filename + '/Images').glob('*.jpg'))\n",
    "  delete_paths = [p for p in Path('/content/drive/MyDrive/part-of-imagenet/partial_imagenet/' + filename + '/Annotation').glob('*.xml') if p.stem not in keep_stems]\n",
    "  for p in delete_paths:\n",
    "      p.unlink()\n",
    "\n",
    "  # now, you should see the same number between xmls and images\n",
    "  len_of_xmls = len(glob.glob1('/content/drive/MyDrive/part-of-imagenet/partial_imagenet/' + filename + '/Annotation','*.xml'))\n",
    "  len_of_imgs = len(glob.glob1('/content/drive/MyDrive/part-of-imagenet/partial_imagenet/' + filename + '/Images','*.jpg')) \n",
    "  print('Total number of xml files after matching each jpg file with its corresponding xml for', filename ,'is', len_of_xmls)\n",
    "  print('Total number of jpg files after matching each jpg file with its corresponding xml for', filename ,'is', len_of_imgs)\n",
    "\n",
    "  # remove csv report file\n",
    "  os.remove(os.path.join('/content/drive/MyDrive/part-of-imagenet/partial_imagenet/' + filename, filename + '_download_report.csv'))\n",
    "\n",
    "\n",
    "  # split the dataset 20% for testing images\n",
    "  os.chdir('/content/drive/MyDrive/part-of-imagenet/partial_imagenet/' + filename + '/Annotation')\n",
    "   \n",
    "  ann_imgs = os.listdir('/content/drive/MyDrive/part-of-imagenet/partial_imagenet/' + filename + '/Annotation')\n",
    "  imgs = os.listdir('/content/drive/MyDrive/part-of-imagenet/partial_imagenet/' + filename + '/Images')\n",
    "  \n",
    "  split = round(0.2*len(imgs))\n",
    "  #print(split)\n",
    "\n",
    "  # take randomly split images from the dataset. \n",
    "  test_images = random.sample(imgs, split)\n",
    "  #print(test_images)\n",
    "  \n",
    "  # for that test_images take their corresponding annotations\n",
    "  for l in test_images:\n",
    "    for m in ann_imgs:\n",
    "      if l[:-3] == m[:-3]:\n",
    "        test_annot.append(m)\n",
    "  print(test_annot)\n",
    "  print(test_images)\n",
    "\n",
    "  # move test_images and their corresponding annotations to seperate folder(test)\n",
    "  for z in test_annot:\n",
    "    shutil.move(os.path.join('/content/drive/MyDrive/part-of-imagenet/partial_imagenet/' + filename + '/Annotation', z), test_dest)\n",
    "  for x in test_images:\n",
    "    shutil.move(os.path.join('/content/drive/MyDrive/part-of-imagenet/partial_imagenet/' + filename + '/Images', x), test_dest)\n",
    "\n",
    "  # keep the rest images with their annotations to seperate folder(train)\n",
    "  src1 = r'/content/drive/MyDrive/part-of-imagenet/partial_imagenet/' + filename + '/Annotation'\n",
    "  src2 = r'/content/drive/MyDrive/part-of-imagenet/partial_imagenet/' + filename + '/Images'\n",
    "\n",
    "  xmls = os.listdir(src1)\n",
    "  imgs = os.listdir(src2)\n",
    "  for f in xmls:\n",
    "    shutil.move(os.path.join(src1, f), train_dest)\n",
    "  for f2 in imgs:\n",
    "    shutil.move(os.path.join(src2, f2), train_dest)\n",
    "\n",
    "\n",
    "  # remove empty needles folders\n",
    "  os.rmdir('/content/drive/MyDrive/part-of-imagenet/partial_imagenet/' + filename + '/Annotation')\n",
    "  os.rmdir(os.path.join('/content/drive/MyDrive/part-of-imagenet/partial_imagenet/' + filename, 'Images'))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPILusX5H3PK"
   },
   "outputs": [],
   "source": [
    "#print(len(os.listdir('/content/drive/MyDrive/image_set4/test')))  # 38 images and 38 xml files as pairs\n",
    "#print(len(os.listdir('/content/drive/MyDrive/image_set4/train'))) # 152 images and 152 xml files as pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouo8QbMzr9MS"
   },
   "source": [
    "images_set4 is now a subset of ImageNet dataset, combrised of 4 classes with maximum 45 images each, 152 in total, for training and maximum 10 images, 38 in total, for testing."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ImageNet_Subset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
